{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SelectKBest, chi2\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION = True\n",
    "\n",
    "train1 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_1_Training.csv',index_col=0).T\n",
    "train2 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_2_Training.csv',index_col=0).T\n",
    "\n",
    "test1 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_1_Testing.csv',index_col=0).T\n",
    "test2 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_2_Testing.csv',index_col=0).T\n",
    "\n",
    "if(VALIDATION):\n",
    "    #Shuffling the dataset\n",
    "    valSize = int(train1.shape[0]*0.75)\n",
    "    train1 = train1.sample(frac=1).reset_index(drop=True)\n",
    "    test1 = train1[valSize:]\n",
    "    train1 = train1[:valSize]\n",
    "    \n",
    "    valSize = int(train2.shape[0]*0.75)\n",
    "    train2 = train2.sample(frac=1).reset_index(drop=True)\n",
    "    test2 = train2[valSize:]\n",
    "    train2 = train2[:valSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 22285)\n",
      "(33, 22285)\n",
      "(255, 54679)\n",
      "(85, 54679)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(train2.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols1 = ['CO: 1','CO: 2']\n",
    "test_cols2 = ['CO: 3','CO: 4','CO: 5','CO: 6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try SMOTE later\n",
    "# def upsample(train,test_cols):\n",
    "#     train_data = train\n",
    "#     for col in test_cols:\n",
    "#         # separate minority and majority classes\n",
    "#         negative = train_data[train_data[col]==0]\n",
    "#         positive = train_data[train_data[col]==1]\n",
    "#         # upsample minority\n",
    "#         pos_upsampled = resample(positive,\n",
    "#          replace=True, # sample with replacement\n",
    "#          n_samples=len(negative), # match number in majority class\n",
    "#          random_state=27) # reproducible results\n",
    "#         # combine majority and upsampled minority\n",
    "#         upsampled = pd.concat([negative, pos_upsampled])\n",
    "#         train_data = upsampled\n",
    "#     return train_data\n",
    "\n",
    "# train1 = upsample(train1,test_cols1)\n",
    "# train2 = upsample(train2,test_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1 = preprocessing.StandardScaler()\n",
    "scaler1.fit(train1.drop(test_cols1, axis=1, errors='ignore'))\n",
    "\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "scaler2.fit(train2.drop(test_cols2, axis=1, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "ytrue = []\n",
    "models = [RandomForestClassifier(n_estimators=750, n_jobs=-1, random_state=0),\n",
    "          AdaBoostClassifier(),\n",
    "          DecisionTreeClassifier(random_state=0),\n",
    "          LogisticRegression(solver='liblinear',penalty='l1'),\n",
    "          SVC(probability=True)]\n",
    "\n",
    "#models = [XGBClassifier()]\n",
    "\n",
    "def pred(test_cols,train,test):\n",
    "    for col in test_cols:\n",
    "        X = train.drop(test_cols, axis=1, errors='ignore')\n",
    "        y = np.array(train[[col]])\n",
    "        y = y.reshape(y.shape[0],)\n",
    "        Xtest = test.drop(test_cols, axis=1, errors='ignore')\n",
    "        \n",
    "        if(VALIDATION): \n",
    "            ytest = test[[col]]\n",
    "            ytrue.extend(list(ytest[col]))\n",
    "\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        scaledX = scaler.fit_transform(X)\n",
    "        pca = PCA()\n",
    "        scaledX = pca.fit_transform(scaledX)\n",
    "#         selector = SelectPercentile(percentile=10)\n",
    "#         scaledX = selector.fit_transform(scaledX,y)\n",
    "#         print(scaledX.shape)\n",
    "        \n",
    "        scaledXtest = scaler.transform(Xtest)\n",
    "        scaledXtest = pca.transform(scaledXtest)\n",
    "#         scaledXtest = selector.transform(scaledXtest)\n",
    "\n",
    "        #model = RandomForestClassifier(n_estimators=750, n_jobs=-1, random_state=0)\n",
    "        #model = AdaBoostClassifier() #Not performing well\n",
    "        #model = LogisticRegression(solver='liblinear',penalty='l1') #Fast\n",
    "        #model = DecisionTreeClassifier(random_state=0) #Not performing well\n",
    "        #model = XGBClassifier()\n",
    "        \n",
    "        stackedX = []\n",
    "        stackedXtest = []\n",
    "        for model in models:\n",
    "            model.fit(scaledX,y)\n",
    "            stackedX.append(model.predict_proba(scaledX)[:,1])\n",
    "            stackedXtest.append(model.predict_proba(scaledXtest)[:,1])\n",
    "            \n",
    "        stackedX = np.array(stackedX).T\n",
    "        stackedXtest = np.array(stackedXtest).T\n",
    "        print(stackedX.shape)\n",
    "        model = DecisionTreeClassifier(random_state=0)\n",
    "        #model.fit(scaledX,y)\n",
    "        model.fit(stackedX,y)  \n",
    "        \n",
    "        #ypred.extend(model.predict(scaledXtest))\n",
    "        ypred.extend(model.predict(stackedXtest))\n",
    "        \n",
    "        #if(VALIDATION): print(col,model.score(scaledXtest,ytest))\n",
    "        if(VALIDATION): print(col,matthews_corrcoef(ytest,model.predict(stackedXtest)),model.score(stackedXtest,ytest))\n",
    "        else: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 5)\n",
      "CO: 1 0.1942057042751279 0.7575757575757576\n",
      "(97, 5)\n",
      "CO: 2 0.24479280153992708 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "pred(test_cols1,train1,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2025090917415868\n"
     ]
    }
   ],
   "source": [
    "if(VALIDATION):\n",
    "    print(matthews_corrcoef(ytrue,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 5)\n",
      "CO: 3 0.23410341035473953 0.8235294117647058\n",
      "(255, 5)\n",
      "CO: 4 -0.03516899742266649 0.8941176470588236\n",
      "(255, 5)\n",
      "CO: 5 0.03669371373282348 0.5411764705882353\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4f3f24bb0239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_cols2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-375431acb561>\u001b[0m in \u001b[0;36mpred\u001b[1;34m(test_cols, train, test)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mscaledX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mscaledX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaledX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#         selector = SelectPercentile(percentile=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#         scaledX = selector.fit_transform(scaledX,y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeeva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeeva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeeva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m         \u001b[1;31m# flip eigenvectors' sign to enforce deterministic output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_flip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeeva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\linalg\\decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# perform decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[0;32m    126\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred(test_cols2,train2,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(VALIDATION):\n",
    "    print(matthews_corrcoef(ytrue,ypred))\n",
    "else:\n",
    "#     submission = pd.DataFrame(ypred,columns=['Predicted'])\n",
    "#     submission.index.name = 'Id'\n",
    "    submission = pd.read_csv('dummy_submission.csv')\n",
    "    submission.Predicted = np.array(ypred,dtype=int)\n",
    "    submission.to_csv('RF2000.csv',index=False)\n",
    "    print(submission.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
