{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, SelectKBest, chi2\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION = True\n",
    "\n",
    "train1 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_1_Training.csv',index_col=0).T\n",
    "train2 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_2_Training.csv',index_col=0).T\n",
    "\n",
    "test1 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_1_Testing.csv',index_col=0).T\n",
    "test2 = pd.read_csv(f'PRML_Datacontest_MKN_JUL_2021/Dataset_2_Testing.csv',index_col=0).T\n",
    "\n",
    "if(VALIDATION):\n",
    "    #Shuffling the dataset\n",
    "    valSize = int(train1.shape[0]*0.7)\n",
    "    train1 = train1.sample(frac=1).reset_index(drop=True)\n",
    "    test1 = train1[valSize:]\n",
    "    train1 = train1[:valSize]\n",
    "    \n",
    "    valSize = int(train2.shape[0]*0.7)\n",
    "    train2 = train2.sample(frac=1).reset_index(drop=True)\n",
    "    test2 = train2[valSize:]\n",
    "    train2 = train2[:valSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 22285)\n",
      "(39, 22285)\n",
      "(237, 54679)\n",
      "(103, 54679)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(train2.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols1 = ['CO: 1','CO: 2']\n",
    "test_cols2 = ['CO: 3','CO: 4','CO: 5','CO: 6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try SMOTE later\n",
    "# def upsample(train,test_cols):\n",
    "#     train_data = train\n",
    "#     for col in test_cols:\n",
    "#         # separate minority and majority classes\n",
    "#         negative = train_data[train_data[col]==0]\n",
    "#         positive = train_data[train_data[col]==1]\n",
    "#         # upsample minority\n",
    "#         pos_upsampled = resample(positive,\n",
    "#          replace=True, # sample with replacement\n",
    "#          n_samples=len(negative), # match number in majority class\n",
    "#          random_state=27) # reproducible results\n",
    "#         # combine majority and upsampled minority\n",
    "#         upsampled = pd.concat([negative, pos_upsampled])\n",
    "#         train_data = upsampled\n",
    "#     return train_data\n",
    "\n",
    "# train1 = upsample(train1,test_cols1)\n",
    "# train2 = upsample(train2,test_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1 = preprocessing.StandardScaler()\n",
    "scaler1.fit(train1.drop(test_cols1, axis=1, errors='ignore'))\n",
    "\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "scaler2.fit(train2.drop(test_cols2, axis=1, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 2229)\n",
      "CO: 1 0.8461538461538461\n",
      "(91, 2229)\n",
      "CO: 2 0.7692307692307693\n",
      "(237, 5468)\n",
      "CO: 3 0.7864077669902912\n",
      "(237, 5468)\n"
     ]
    }
   ],
   "source": [
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "def pred(test_cols,train,test):\n",
    "    for col in test_cols:\n",
    "        X = train.drop(test_cols, axis=1, errors='ignore')\n",
    "        y = np.array(train[[col]])\n",
    "        y = y.reshape(y.shape[0],)\n",
    "        Xtest = test.drop(test_cols, axis=1, errors='ignore')\n",
    "        \n",
    "        if(VALIDATION): \n",
    "            ytest = test[[col]]\n",
    "            ytrue.extend(list(ytest[col]))\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaledX = scaler.fit_transform(X)\n",
    "#         pca = PCA()\n",
    "#         scaledX = pca.fit_transform(scaledX)\n",
    "        selector = SelectPercentile(chi2, percentile=10)\n",
    "        scaledX = selector.fit_transform(scaledX,y)\n",
    "        print(scaledX.shape)\n",
    "        \n",
    "        scaledXtest = scaler.transform(Xtest)\n",
    "#         scaledXtest = pca.transform(scaledXtest)\n",
    "        scaledXtest = selector.transform(scaledXtest)\n",
    "\n",
    "        #model = RandomForestClassifier(n_estimators=2000, n_jobs=-1, random_state=0)\n",
    "        #model = AdaBoostClassifier() #Not performing well\n",
    "        #model = LogisticRegression(solver='liblinear',penalty='l1') #Fast\n",
    "        #model = DecisionTreeClassifier() #Not performing well\n",
    "        model = XGBClassifier()\n",
    "        model.fit(scaledX,y)\n",
    "        ypred.extend(model.predict(scaledXtest))\n",
    "        \n",
    "        if(VALIDATION): print(col,model.score(scaledXtest,ytest))\n",
    "        else: print(col)\n",
    "\n",
    "pred(test_cols1,train1,test1)\n",
    "pred(test_cols2,train2,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(VALIDATION):\n",
    "    print(matthews_corrcoef(ytrue,ypred))\n",
    "else:\n",
    "#     submission = pd.DataFrame(ypred,columns=['Predicted'])\n",
    "#     submission.index.name = 'Id'\n",
    "    submission = pd.read_csv('dummy_submission.csv')\n",
    "    submission.Predicted = np.array(ypred,dtype=int)\n",
    "    submission.to_csv('RF2000.csv',index=False)\n",
    "    print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
